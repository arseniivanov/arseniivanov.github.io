[
  {
    "file": "2025-07-17-information-dtype-representations.md",
    "title": "Why FP4 is not a free lunch for ML",
    "date": "July 17, 2025",
    "id": "fp4-ml",
    "tags": ["Neural Networks"]
  },
  {
    "file": "2025-08-13-the-expressive-power-of-activation-functions.md",
    "title": "The expressive power of activation functions",
    "date": "August 13, 2025",
    "id": "activation-functions",
    "tags": ["Neural Networks"]
  },
  {
    "file": "2025-08-20-the-metric-misalignment.md",
    "title": "The metric misalignment in (Computer Graphics) compression research",
    "date": "August 20, 2025",
    "id": "metric-misalignment",
    "tags": ["Computer Graphics", "Research"]
  },
  {
    "file": "2025-09-09-feedback-on-llm-written-work.md",
    "title": "Feedback on LLM-written work",
    "date": "September 9, 2025",
    "id": "llm-feedback",
    "tags": ["LLM", "Education"]
  },
  {
    "file": "2025-09-17-moe.md",
    "title": "Why the MoE pattern is inevitably a part of the future of compute in ML",
    "date": "September 17, 2025",
    "id": "moe-future",
    "tags": ["Neural Networks", "Compute"]
  },
  {
    "file": "2025-10-01-trimul.md",
    "title": "Making Trimul go BRRRR for GPGPU",
    "date": "October 1, 2025",
    "id": "trimul-gpgpu",
    "tags": ["GPGPU", "Optimization"]
  },
  {
    "file": "2025-10-12-softmax.md",
    "title": "What does attention represent and why do we need softmax?",
    "date": "October 12, 2025",
    "id": "attention-softmax",
    "tags": ["LLM", "Compute", "Information Theory", "GPGPU", "Neural Networks"]
  }
]
